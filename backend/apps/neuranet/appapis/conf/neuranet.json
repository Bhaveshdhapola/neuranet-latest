{
    "crypt_key":"82577als2141rwq294938wasj3029ldwpz",
    "ai_key": "3d4900d278e13fb8f799d4f10aad58c1aa30bb075a83f477b84da5f48bc0921af74df99d74fa6fd5bd950d7e0982c85c4701b0079d197c7493c708",
    "ai_model_default": "chat-gpt35-turbo",
    "debug_mode": true,

    "ai_models": {
        "sql-code-gen35": {
            "driver":{"module":"ailibGPT35.js", "host":"api.openai.com", "port":443, "path":"/v1/chat/completions"}, 
            "request":{ 
                "model": "gpt-3.5-turbo", "temperature": 0, "stream": false, "max_tokens": 1024, 
                "presence_penalty": 0, "frequency_penalty": 0,  "top_p": 1, "stop":["---"], 
                "messages":[{"role": "user", "content": "${__ORG_NEURANET_PROMPT__}"}] 
            },
            "response_contentpath": "data.choices[0].message.content",
            "response_finishreason": "data.choices[0].finish_reason",
            "response_cost_of_query_path": "data.usage.total_tokens",
            "sample_ai_response": "sql_ai_response.json",
            "read_ai_response_from_samples": false
        },

        "chat-gpt35-turbo": {
            "driver":{"module":"ailibGPT35.js", "host":"api.openai.com", "port":443, "path":"/v1/chat/completions"}, 
            "request":{ 
                "model": "gpt-3.5-turbo", "temperature": 0.7, "stream": false, "max_tokens": 4096, 
                "presence_penalty": 0, "frequency_penalty": 0,  "top_p": 1
            },
            "request_contentpath": "messages",
            "response_contentpath": "data.choices[0].message.content",
            "response_finishreason": "data.choices[0].finish_reason",
            "response_cost_of_query_path": "data.usage.total_tokens",
            "sample_ai_response": "chat_ai_response.json",
            "read_ai_response_from_samples": true
        },

        "lang-code-gen35": {
            "driver":{"module":"ailibGPT35.js", "host":"api.openai.com", "port":443, "path":"/v1/chat/completions"}, 
            "request":{ 
                "model": "gpt-3.5-turbo", "temperature": 0, "stream": false, "max_tokens": 4096, 
                "presence_penalty": 0, "frequency_penalty": 0,  "top_p": 1, 
                "messages":[{"role": "user", "content": "${__ORG_NEURANET_PROMPT__}"}] 
            },
            "response_contentpath": "data.choices[0].message.content",
            "response_finishreason": "data.choices[0].finish_reason",
            "response_cost_of_query_path": "data.usage.total_tokens",
            "sample_ai_response": "code_ai_response.json",
            "read_ai_response_from_samples": false
        },

        "lang-code-chaingen35": {
            "driver":{"module":"ailibGPT35.js", "host":"api.openai.com", "port":443, "path":"/v1/chat/completions"}, 
            "request":{ 
                "model": "gpt-3.5-turbo", "temperature": 0, "stream": false, "max_tokens": 2048, 
                "presence_penalty": 0, "frequency_penalty": 0,  "top_p": 1, 
                "messages":[{ "role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "${__ORG_NEURANET_PROMPT__}"}] 
            },
            "response_contentpath": "data.choices[0].message.content",
            "response_finishreason": "data.choices[0].finish_reason",
            "response_cost_of_query_path": "data.usage.total_tokens",
            "sample_ai_response": "chaincode_model_response.json",
            "read_ai_response_from_samples": false
        }
    }
}