# This YAML file is the core of any AI application. The ID in the file, the file name and the hosting folder must
# match. The file documents rest of the commands and syntax.

---
id: tkmsearchaiapp                          # the AI application name / ID
interface:                                  # the interface details
  type: search                              # this is for the frontend can be chat, translate or search interfaces
  label: AI search                          # the label for the app icon on the UI
  icon: data:image/svg+xml;base64,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
  skippable_file_patterns: 
    - ^_neuranet_generated?.+
    - ^\.system?.+
endpoint: llmflow                           # the API endpoint - usually llmflow
users: ["*"]                                # the * means all users, else must be an array of user IDs
admins: ["thecompany@tekmonks.com"]         # the admins for this app - they can train for example
api_uploads_cms_path: uploads               # where files are uploaded by index, unindex APIs
generated_files_path: _neuranet_generated

# all flows are sequence of commands which follow the same syntax - command, in, out - in is the input
# to the command, out is the variable holding the output and name points to the command module and entry
# point. the command sytax is documented below as well.

pregen_flow: 
  - command: rephrasedoc.generate           # module and entry function can be used using module.entry
    in: 
      label: Simplified

      prompt: |
        Rephrase the document below in simple language in less than {{{words}}} words.
        {{{fragment}}}
      prompt_zh: |
        用少于 {{{words}}} 个单词的简单语言重新表述以下文档。
        {{{fragment}}}
      prompt_ja: |
        以下の文書を {{{words}}} 語以内で簡単な言葉で言い換えてください。
        {{{fragment}}}
      prompt_hi: |
        नीचे दिए गए दस्तावेज़ को सरल भाषा में {{{words}}} से कम शब्दों में दोबारा लिखें।
        {{{fragment}}}

      models: 
        - name: simplellm-gpt35-turbo
          type: chat
          model_overrides:                  # this allows us to override model params on a per AI app basis, can be a nested path e.g. driver.host if we are calling API at a different host name etc          
            read_ai_response_from_samples: true
        - name: embedding-openai-ada002
          type: embeddings
          model_overrides:                      
            read_ai_response_from_samples: true
      words_promptparam: 700
      pregenfile_prefix: summary
      pregenfile_dir: _neuranet_generated
      pregenfile_ext: txt
      encoding: utf8

  - command: rephrasedoc                    # entry function name is skipped as the default is generate anyways
    in: 
      label: Rephrased

      prompt: |                             # these can be prompt, prompt_docISOLanguage, prompt_fragment_fragmentISOLanguage
        Infer the document and rephrase it in a more generic context that most people without expertise or knowledge can understand.
        {{{fragment}}}
      prompt_zh: |
        文書を推測し、専門知識や知識を持たないほとんどの人が理解できる、より一般的な文脈で言い換えます。
        {{{fragment}}}
      prompt_ja: |
        文書を推測し、専門知識や知識を持たないほとんどの人が理解できる、より一般的な文脈で言い換えます。
        {{{fragment}}}
      prompt_hi: |
        दस्तावेज़ का अनुमान लगाएं और इसे अधिक सामान्य संदर्भ में दोबारा लिखें जिसे विशेषज्ञता या ज्ञान के बिना अधिकांश लोग समझ सकें।
        {{{fragment}}}

      models: 
        - name: simplellm-gpt35-turbo
          type: chat
          model_overrides:                  # this allows us to override model params on a per AI app basis, can be a nested path e.g. driver.host if we are calling API at a different host name etc          
            read_ai_response_from_samples: true
        - name: embedding-openai-ada002
          type: embeddings
          model_overrides:                      
            read_ai_response_from_samples: true
      pregenfile_prefix: reworded
      pregenfile_dir: _neuranet_generated
      pregenfile_ext: txt
      encoding: utf8

docsearch_flow:
  - command: doctfidfsearch.search          # if forced return true, else for double-byte (cn and ja) return true
    condition_js: |
      if (request.force_nonllm_search) return true; 
      const langdetector = require(`${NEURANET_CONSTANTS.THIRDPARTYDIR}/langdetector.js`);
      const lang = langdetector.getISOLang(queryJSON); if ((lang == "zh") || (lang == "ja")) return true; else return false;
    in: 
      query: "{{{query}}}"                  # inbuilt variable contains the user's query
      metadata: null
      topK_tfidf: 3
      cutoff_score_tfidf_js: request.cutoff_score_tfidf || 0.40
      topK_vectors: 3
      min_distance_vectors: 0
      aiappid: "{{{aiappid}}}"  
      bridges_js: return (request.bridges||[aiappid])
      metadata_filter_function: "{{{request.metadata_filter_function}}}"
      punish_verysmall_documents_js: "return request.punish_verysmall_documents !== undefined ? request.punish_verysmall_documents : false"
    out: airesponse.documents

  - command: docvectorsearch.search         # if forced return true, else for non double-byte (cn and ja) return true
    condition_js: |
      if (request.force_llm_search) return true; 
      const langdetector = require(`${NEURANET_CONSTANTS.THIRDPARTYDIR}/langdetector.js`);
      const lang = langdetector.getISOLang(queryJSON); if ((lang == "zh") || (lang == "ja")) return false; else return true;
    in: 
      query: "{{{query}}}"
      topK_tfidf: 3
      cutoff_score_tfidf_js: request.cutoff_score_tfidf || 0.40
      topK_vectors: 3
      min_distance_vectors: 0
      embeddings_model: 
        name: embedding-openai-ada002
        model_overrides:                    
          read_ai_response_from_samples: true
      aiappid: "{{{aiappid}}}"  
      bridges_js: return (request.bridges||[aiappid])
      metadata_filter_function: "{{{request.metadata_filter_function}}}"
      punish_verysmall_documents_js: "return request.punish_verysmall_documents !== undefined ? request.punish_verysmall_documents : false"
    out: airesponse.documents


global_models:
  - name: embedding-openai-ada002
    model_overrides:                    
      read_ai_response_from_samples: true

  - name: chat-knowledgebase-gpt35-turbo
    model_overrides:                    
      read_ai_response_from_samples: true

  - name: simplellm-gpt35-turbo
    model_overrides:                    
      read_ai_response_from_samples: true


modules: 
  llm_history_chat: llm_history_chat.js
